#+TITLE: ML IN PRACTICE - TYPES OF MODELS
#+AUTHOR: Marcus Birkenkrahe
#+STARTUP: overview hideblocks indent
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* ML in practice
* Process
#+attr_html: :width 500px
#+caption: DataCamp "Understanding ML" course
[[../img/1_dc_ml_flow.png]]

1. *Data collection*: The data collection step involves gathering the
   learning material an algorithm will use to generate actionable
   knowledge. In most cases, the data will need to be combined into a
   single source, such as a text file, spreadsheet, or database.

2. *Data exploration and preparation*: The quality of any machine
   learning project is based largely on the quality of its input
   data. Thus, it is important to learn more about the data and its
   nuances during a practice called data exploration. Additional work
   is required to prepare the data for the learning process. This
   involves fixing or cleaning so-called "messy" data, eliminating
   unnecessary data, and recoding the data to conform to the learner's
   expected inputs.

3. *Model training*: By the time the data has been prepared for
   analysis, you are likely to have a sense of what you are capable of
   learning from the data. The specific machine learning task chosen
   will inform the selection of an appropriate algorithm, and the
   algorithm will represent the data in the form of a model.

4. *Model evaluation*: Each machine learning model results in a biased
   solution to the learning problem, which means that it is important
   to evaluate how well the algorithm learned from its
   experience. Depending on the type of model used, you might be able
   to evaluate the accuracy of the model using a test dataset, or you
   may need to develop measures of performance specific to the
   intended application.

5. *Model improvement*: If better performance is needed, it becomes
   necessary to utilize more advanced strategies to augment the
   model's performance. Sometimes it may be necessary to switch to a
   different type of model altogether. You may need to supplement your
   data with additional data or perform additional preparatory work,
   as in step two of this process.

6. *Model deployment*: if the model appears to be performing well, it
   can be deployed for its intended task. As the case may be, you
   might utilize your model to provide score data for predictions
   (possibly in real time); for projections of financial data; to
   generate useful insight for marketing or research; or to automate
   tasks, such as mail delivery or flying aircraft. The successes and
   failures of the deployed model might even provide additional data
   to train your next-generation learner.

* Units of observation vs. analysis

- A *unit of observation* is the smallest entity with measured
  properties of interest for a study. Commonly, the unit of
  observation is in the form of persons, objects or things,
  transactions, time points, geographic regions, or
  measurements. Sometimes, units of observation are combined to form
  units, such as person-years, which denote cases where the same
  person is tracked over multiple years, and each person-year
  comprises a person's data for one year.

- The *unit of analysis* is the smallest unit from which inference is
  made. Although it is often the case, the observed and analyzed units
  are not always the same. For example, data observed from people (the
  unit of observation) might be used to analyze trends across
  countries (the unit of analysis).

- Distinguish *example*, instances of the unit of observation for which
  properties were recorded, and *features*, the recorded properties or
  attributes of examples that may be useful for ML

- Use case: spam email identification. The unit of observation could be
  email messages, examples would be specific individual messages, and
  the features might consist of the words used in the messages.

- Use case: cancer detection. The unit of observation could be
  patients, the examples might be a random sample of cancer patients,
  and the features genomic markers from biopsied cells, and patient
  characteristics like weight, height, blood pressure.

* Structured vs. unstructured data

- Humans can consume /unstructured/ data - free-form text, pictures,
  sound, and they can handle cases with many or few features
- Computers required data to be /structured/ - each example of the
  phenomenon has the same features, which are organized in data
  structures like tables or matrices or data frames

- In data tables, matrices or data frames, rows correspond to examples
  or records or observations of features, which correspond to columns

- Data entries can have different types: /numeric-discrete/,
  /numeric-continuous/, /categorical-nominal/, or /categorical-ordinal/

- Clarity about features, observations, and data types is crucial for
  selecting the best learning algorithm

* Types of ML algorithms
#+attr_html: :width 400px
[[../img/3_ml_models.png]]

Machine learning algorithms are divided into categories according to
their purpose. Understanding the categories of learning algorithms is
an essential first step toward using data to drive the desired action.

* Predictive models - supervised learning - classification

- *Predictive models* involve prediction of one value using other values
  in the same dataset. The algorithm models the relationship between
  the target feature (predicted) and the other features (predictors).

- These models do not need to be forecasting models (for the future),
  they can also predict past events or work in real-time.

- The process of training a predictive model is called *supervised
  learning*. The "supervision" refers to the fact that the target
  values let the learner (the machine) know how well it's doing.

- Given a set of data, a *supervised learning algorithm* optimizes a
  *function* (the *model*) to find the combination of *feature* input values
  that result in the *target* output.

- *Classification* means predicting which category an example belongs
  to. The corresponding supervised ML algorithm is a *classifier*, e.g.
  1) An email message is spam
  2) A person has cancer
  3) A football team will win or loose
  4) An applicant will default on a loan

- The classification target feature is the *class*, which is divided
  into category values called *levels*, which may be nominal or ordinal

- The most widely used supervised learning algorithm for *numeric
  prediction*, especially forecasting, is *linear regression*

- Since discrete numbers can be converted to categories, the boundary
  between classification and numeric prediction models is blurry

* Descriptive models - unsupervised learning - clustering

- *Descriptive models* are used to summarize data in new and interesting
  ways. No single feature is more important than any other.

- Because there is no target to be supervised, the process of training
  a descriptive model is called *unsupervised learning*.

- An example is *pattern discovery* in *data mining* to identify useful
  associations (correlations) within data. An application is *market
  basket analysis* of transactional purchase data in retail: if the
  retailer learns that swimming trunks are purchased at the same time
  as sunscreen, it could use this information when marketing both
  products, e.g. reposition them in the store, run a promotion etc.

- *Clustering* is descriptive modeling - it means dividing a dataset
  into homogenous groups. This can be used for *segmentation analysis*
  to identify groups of individuals with similar behavior or
  demographics, e.g. to create a "people like you have
  bought this item, too" type of promotion.

* Meta-learners - ensembles - reinforcement learning

- *Meta-learners* are models that learn how to learn more effectively by
  using the result of past learning to inform additional learning

- *Ensembles* are algorithms that work in teams, and algorithms that
  evolve over time in a process called *reinforcement learning*

- *Adversarial learning* involves learning about a model's weaknesses in
  order to harden it against malicious attacks

- The popular *ChatGPT* model is a natural-language processing (NLP)
  variant of the GPT-3 (Generative Pertained Transformer 3) model,
  which was trained in massive amount of text data to generate
  human-like responses to a given input.
  #+attr_html: :width 500px
  [[./img/ml_chatgpt.png]]

  The image shows ChatGPT output via Google Chrome extension (right)
  next to "classic" Google search engine output (left)

- List of Supervised Learning algorithms

  | NAME                    | TYPE               | CHAPTER |
  |-------------------------+--------------------+---------|
  | Naive Bayes             | Classification     |       4 |
  | Decision trees          | Classification     |       5 |
  | Linear regression       | Numeric prediction |       6 |
  | Regression trees        | Numeric prediction |       6 |
  | Model trees             | Numeric prediction |       6 |
  | Neural networks         | Dual use           |       7 |
  | Support Vector Machines | Dual use           |       7 |
  |-------------------------+--------------------+---------|

- List of Unsupervised Learning algorithms
  | NAME               | TYPE              | CHAPTER |
  |--------------------+-------------------+---------|
  | Association rules  | Pattern detection |       8 |
  | k-means clustering | Clustering        |       9 |

- Meta-learning algorithms
  | NAME           | TYPE     | CHAPTER |
  |----------------+----------+---------|
  | Bagging        | Dual use |      11 |
  | Boosting       | Dual use |      11 |
  | Random forests | Dual use |      11 |

* ML with R
* R packages

- R is free, open source software (FOSS) for statistical programming
- Many ML algorithms must be installed on top of base R as packages
- Both base R and packages can be obtained from CRAN, the
  Comprehensive R Archive Network (CRAN), at [[https://cran.r-project.org][cran.r-project.org]]
- There is a [[https://cran.r-project.org/web/views/MachineLearning.html][separate /task view/ for ML on CRAN]]

* The ~RWeka~ package

- ~RWeka~ was developed by Hornik et al (2009). [[http://www.cs.waikato.ac.nz/~ml/weka/][See here]] for more
  information on ~weka~) - you also need to have [[http://www.java.com/][Java]] installed

- When installing the package with ~install.packages~, required
  /dependencies/ (other packages) will also be installed

- When installing, pick a mirror near you for greater download speed

- The /default/ location will be announced at the end of the install, or
  your system may ask you to specify a location (accept the default)

- You could also specify a location to install using the ~lib~ parameter:
  #+begin_example R
  > install.packages("RWeka", lib = "/path/to/library")
  #+end_example

- To load the package, use the ~library~ function. To see it in the work
  environment, use ~search()~, and to detach it from the current
  session, use ~detach~:
  #+begin_src R
    library(RWeka)
    search()
    detach("package:RWeka", unload=TRUE)
    search()
  #+end_src

  #+RESULTS:
  #+begin_example
   [1] ".GlobalEnv"        "package:RWeka"     "package:lattice"
   [4] "package:MASS"      "package:scales"    "package:ggplot2"
   [7] "ESSR"              "package:stats"     "package:graphics"
  [10] "package:grDevices" "package:utils"     "package:datasets"
  [13] "package:methods"   "Autoloads"         "package:base"
   [1] ".GlobalEnv"        "package:lattice"   "package:MASS"
   [4] "package:scales"    "package:ggplot2"   "ESSR"
   [7] "package:stats"     "package:graphics"  "package:grDevices"
  [10] "package:utils"     "package:datasets"  "package:methods"
  [13] "Autoloads"         "package:base"
  #+end_example

* RStudio

- RStudio is an additional interface to R available at
  https://www.rstudio.com

- RStudio includes:
  1) an integrated code editor
  2) an R command-line console
  3) a file browser
  4) code output, plot, graphics
  5) project and package management
  6) integration with source / version control tools
  7) database connection maangement
  8) compilation of R output to HTML, PDF, WORD

- RStudio Notebook formats allow for literate programming


* Summary

- The ML model is used for prescriptive or descriptive purposes
- ML purposes can be: category classification, numeric prediction,
  pattern detection, and clustering
- Algorithms are chosen based on input data and learning task
- R supports ML through community-authored, FOSS packages that need to
  be installed and loaded

* References

- Anderson (2017). Twenty years on from Deep Blue vs Kasparov: how a
  chess match started the big data revolution. [[https://theconversation.com/twenty-years-on-from-deep-blue-vs-kasparov-how-a-chess-match-started-the-big-data-revolution-76882][@theconversation.com.]]

- Hosseini, Z., Hytönen, K., & Kinnunen, J. (2022). Improving Online
  Content Quality Through Technological Pedagogical Content Design
  (TPCD). In S. Vachkova, & S. S. Chiang (Eds.), Education and City:
  Quality Education for Modern Cities, vol 3. European Proceedings of
  Educational Sciences (pp. 284-296). European
  Publisher. https://doi.org/10.15405/epes.22043.25

- Lantz (2019). Machine Learning with R. Packt.

- Roiger (2020). Just Enough R!. CRC Press.

- Serrano (2021). Grokking Machine Learning.

