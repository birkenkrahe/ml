#+TITLE: Linear Regression - Exploring the model 
#+AUTHOR: Victor Noppe, Andrei Galca, and Pedro Mota
#+SUBTITLE: Sprint reviews
#+STARTUP: overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil

* DONE Sprint review 1
** Problem

  Evaluate the performance of Linear Regression and Random Forest models.
  
** Reason

  To get a better understanding of how machine learning models work
  and how to evaluate their accuracy.
  
** Constraints

  1. Since the team is currently working on multiple projects, time to
  meet will be a challenge to overcome.
  
  2. Limited experience with Python.

  3. Limited experience with Machine Learning.
  
** Goals and Non-goals
** Goals

   1. To better understand Machine Learning and how Machine Learning
      models are implemented.

   2. To create an engaging and informative presentation.

   3. To be abble to illustrate the comparison between Linear
      Regression and Random Forest (non-linear regression) models in a
      clear and understandable manner.
   
** Non-goals

   1. Becoming more confortable with presenting from a professional
      standpoint.

   2. Becoming more familiar with Python.
   
** Plan

  1. Complete the youtube guide found for this project.

  2. Meet on a regular basis to discuss the research found on Linear
     Regression model and Random Forest Model.

  3. Help each other obtain the same confort with the proposed topic
     for this project.

  4. Find literature to help develop and reinforce the topic of our
     project.
  
** Metrics

  1. The amount of knowledge we are able to obtain and relay to or classmates.

  2. How engaged our classmates are with our presentation.

  3. Were we able to fit the presentation to the allotted time frame.   

  4. The overall grade we obtain for this project.
  
** Questions

  
  1. Is this a valid idea for a project?

  2. What is the proper citation for the emacs and org-mode software?

  3. Are there any source that you could recommend on Linear
     Regression models and Random Forest models?
  
** References

  Chanin Nantasenamat Ph.D., 2022, Build your first machine learning model in Python,
  https://www.youtube.com/watch?v=29ZQ3TDGgRQ

* DONE Sprint review 2
** Literature Review 1

- Reference

  Real Python, "Linear Regression in Python", Real Python, 24 May. 2022 [[https://realpython.com/linear-regression-in-python/][Linear Regression]]

  The article "Linear Regression in Python" provides a comprehensive
  guide on performing linear regression. The article begins by
  covering basic concepts of linear regression such as what is this
  model and what types it has. Then the article revolves around how to
  perform multiple linear regressions using Pandas and how to
  interpret the results with statistical metrics such as R-squared and
  p-value. In this section, the article also explains some aspects of
  scikit-learn, a popular machine learning library, and shows how to
  perform a linear regression model and how to evaluate it using
  cross-validation. Finally, the article gives some examples of best
  practices for performing linear regression, such as data
  preprocessing and feature selection. Overall, the article provides a
  detailed explanation of the logic and the principles behind linear
  regression and gives code examples of each step while building the
  model. That aspect of this article helped us to define how we will
  build the model and what aspects of this process will be more
  important to focus on during the project.

- Evaluation

  This article was enlighting to the point where we changed the the
  focus of our project to only focus on Linear Regression instead of
  comparing it to the Random Forest model. The main reason for that
  was the amount of information this article could provide us
  regarding Linear Regression. The article does a good job to separate
  its content into sections, so that we can have a clear vision of the
  sequence of steps we must have to forecast results with Linear
  Regression. It is a good article for someone who is looking to
  understand what is Linear Regression and what does do, to the point
  where even though nobody on the team had experience with Python
  programming we could understand the progress we were making while
  following the steps in the tutorial within the article. Although, we
  think it would be good if the author included a section focusing on
  plotting the resulting data once the results were calculated with
  the model.
    
** Literature Review 2

- Reference

  Porras, E. M,"Linear Regression in R Tutorial", DataCamp, 18 Jul. 2018 [[https://www.datacamp.com/tutorial/linear-regression-R][Linear Regression in R]]

- Summary

 The article "Linear Regression in R Tutorial" by Eladio Porras is a
  comprehensive guide that discusses the basics of the Linear
  Regression model in R. Like "Linear Regression in Python" the
  article initially explains the theory behind the model and provides
  examples of situations where simple and multiple linear regression
  models can be used in R. The author explains how R calculates linear
  regression with the lm() function by implementing a simple
  model. Next, the article explains how to implement multiple linear
  regression also using lm() function by providing examples of the use
  of multiple variables to forecast a dependent variable. The article
  also covers the interpretation of the results obtained with linear
  regression and the evaluation of the model's performance using
  metrics such as the R-squared value. The tutorial also mentions the
  eventual presence of Influential Points that might happen for errors
  while collecting the data or cases that linear regression cannot
  account for. Overall, the article complemented [[https://realpython.com/linear-regression-in-python/][Linear Regression in
  Python]] and offered us valuable information on the machine learning
  model in a language that is more familiar to the members of the
  team.

- Evaluation

  This article gave an easier-to-comprehend explanation of the
  fundamentals of linear regression. It had a different approach than
  [[https://realpython.com/linear-regression-in-python/][Linear Regression in Python]], while the first one used handmade data,
  this article used an actual excel file using other features of the R
  language. Although this article had fewer code blocks, it did a
  better job illustrating with different plots the results that can be
  generated by a linear regression model. This seemed a credible
  source, since the content in this article matched most parts of the
  first article, and it was published on a platform used for Lyon
  College Data Science courses. We would highly recommend this article
  for someone who is not clear on what is linear regression and how it
  can be implemented.

** References
 Stallman, R. M. (1984). The Emacs editor. GNU Project. [[https://www.gnu.org/software/emacs/][emacs]]
 Schulte, E., Davison, C., & Dominik, C. (2016). The Org mode 8 Reference Manual. [[https://orgmode.org/manual/][org-mode]]
 
* DONE Sprint review 3
** Abstract

- Regression models look for relationships between variables, and
  linear regression is one of the most simple and easy-to-interpret
  models out there, it is a statistical model that analyses the
  relationships between a response variable and an explanatory
  variable.  When a linear regression model is set, we are assuming
  that the variables at hand have a linear relation, which can
  translate as this function (~y = a + bx~). Where, *y* is the response
  variable, *a* is the intercept, *b* is the slope, and *x* is the
  explanatory variable. Response variables are the outputs, also
  called dependent variables. Explanatory variables are predictors,
  also called independent variables. We can use linear regression to
  forecast values based on the relationships the independent and
  dependent variables have. We mesure the relationships in terms of
  correlation, which can have values from -1 to 1, indicating how much
  the variables change together. With all those concepts explained we
  could conclude that having a decent background on the data analyzed
  is crucial for identifying linear relations and selecting variables
  for a linear regression model. To manipulate the ~mtcars~ data frame,
  we selected the miles per gallon (~mpg~) and weight (~wt~) variables to
  create a linear regression model. To evaluate if a model can be
  accepted or not we look into the p-value coefficients. The smaller
  these coefficients are, then higher is the indication that the
  variable at hand will be a good addition to the model. Looking at
  the performance of the model we built, weight had a p-value of
  5.20e-07 in relation to ~mpg~. When we visualized the results, it
  could be concluded that the heavier the car is, the fewer miles a
  car will travel per gallon of fuel. With this result, we could see
  how intuitive and useful linear regression can be for evaluating
  relationships between variables and how important it is for the data
  scientist to have knowledge regading the data used in the model.
  
** Results
#+TITLE: Linear Regression - Exploring the model
#+AUTHOR: Victor Noppe, Andrei Galca, and Pedro Mota
#+SUBTITLE: Sprint reviews
#+STARTUP: overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both

*** README

- This presentation will go through the concepts of Linear Regression
  model. After this you will understand how to build a model, load de
  data, forecast outcomes with the model, visualize and evaluate the
  performace of the fitting model.
  
*** What is Linear Regression?

  - Linear Regression is a Machine Leaning model that calculates
    predictions based on the relationship of different
    variables. Examples of these correlations could be the price of a
    house and the amount of stores nearby, the weight of a person
    and their height, and the amount of money earned with the
    amount of hours worked.

    These variables are separated into two groups:

  *- Dependent Variables*
    These are the predicted values, also called response variables or
    output.

  *- Independent Variables*
    These are the variables used to calculate the output, they are also
    called explanatory variables or predictors.

    A dependent variable can have multiple relationships with
    independant variables. For example, the height of a child can be
    related to the age and weight it has.

*** What is the basic structure of Linear Regression?

- The linear regression model can be defined in a single function
  command:

  ~lm(dependent_variable ~ independent_variable, data = data_frame_x)~

  This is the basic function that is used to create a Linear
  Regression model. While implementing the model of some response
  variable on a set of explanatory variables, it is assumed that
  there is a linear relation between those two. This linear relation
  can be described by:

  y = response variable
  a = intercept (y value where x = 0)
  b = slope (angle of the line)
  x = explanatory variable
  
 [[file:equaimage.png]]

 Or in the case o multiple explanatory variables:

 y = response variable
 beta0 = intercept (y value where all x = 0)
 betar = regression coefficients
 xr = explanatory variables
 epsilon = random error
 
 [[file:equaimagebeta.png]]

*** Understanding the model
- Let's start creating a model for the mtcars dataframe. In this model
  we will be looking into the relation between the mpg(miles per
  gallon) values and the wt(weight) of the cars.

  For better data visualization we will be using the ggplot2 package.
  
  #+begin_src R
    library(ggplot2)
  #+end_src

  #+RESULTS:
  : Warning message:
  : package 'ggplot2' was built under R version 4.1.3
  
  In this block we will:
  - Load the data
  - Separate and visualize the important variable for the model

  #+begin_src R
    data("mtcars")
    head(mtcars)
  #+end_src

  #+RESULTS:
  :                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
  : Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
  : Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
  : Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
  : Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
  : Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
  : Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

  Looking at the ~mtcars~ header we can see that the miles per gallon (~mtcars$mpg~)
  and weight (~mtcars$wt~) variables are promissing to have a linear relation
  between them. As the weight of a car increases the engine tends to
  use more fuel to move the car.

  #+begin_src R :results graphics file :file mtcars_scatterplot.png
    ggplot(mtcars, aes(mtcars$mpg, mtcars$wt)) + geom_point()
  #+end_src

  #+RESULTS:
  [[file:mtcars_scatterplot.png]]
  
**** Coefficients
With the summary function we can find out information regarding:
- Model's performance: error

#+begin_src R
summary(carModel)
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,	Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
#+end_example

Let's dive in on the details ~summary()~ returned to us:

*** Loading the data
- First we load the built in data frame mtcars from R and take a look
  on the structure and first elements to see which variables might fit
  a linear regression well.
  
#+begin_src R
  data("mtcars")
  head(mtcars)
  str(mtcars)
  mtcars
#+end_src

#+RESULTS:
#+begin_example
 [1] ".GlobalEnv"        "ESSR"              "package:stats"    
 [4] "package:graphics"  "package:grDevices" "package:utils"    
 [7] "package:datasets"  "package:methods"   "Autoloads"        
[10] "package:base"
                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
'data.frame':	32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb
Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
#+end_example

#+begin_src R
  relation <- mtcars[,c(1,6)]
  relation
#+end_src

#+RESULTS:
#+begin_example
                     mpg    wt
Mazda RX4           21.0 2.620
Mazda RX4 Wag       21.0 2.875
Datsun 710          22.8 2.320
Hornet 4 Drive      21.4 3.215
Hornet Sportabout   18.7 3.440
Valiant             18.1 3.460
Duster 360          14.3 3.570
Merc 240D           24.4 3.190
Merc 230            22.8 3.150
Merc 280            19.2 3.440
Merc 280C           17.8 3.440
Merc 450SE          16.4 4.070
Merc 450SL          17.3 3.730
Merc 450SLC         15.2 3.780
Cadillac Fleetwood  10.4 5.250
Lincoln Continental 10.4 5.424
Chrysler Imperial   14.7 5.345
Fiat 128            32.4 2.200
Honda Civic         30.4 1.615
Toyota Corolla      33.9 1.835
Toyota Corona       21.5 2.465
Dodge Challenger    15.5 3.520
AMC Javelin         15.2 3.435
Camaro Z28          13.3 3.840
Pontiac Firebird    19.2 3.845
Fiat X1-9           27.3 1.935
Porsche 914-2       26.0 2.140
Lotus Europa        30.4 1.513
Ford Pantera L      15.8 3.170
Ferrari Dino        19.7 2.770
Maserati Bora       15.0 3.570
Volvo 142E          21.4 2.780
#+end_example

#+begin_src R
  wtMpg <- lm(mpg ~ wt, mtcars)
  summary(wtMpg)
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,	Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
#+end_example


#+begin_src R :results graphics file :file mtcars_1.png
  library("ggplot2")
  search()
  ggplot(mtcars, aes(mtcars$wt, mtcars$mpg)) + geom_point() + geom_smooth(method=lm, se = FALSE)
#+end_src

#+RESULTS:
[[file:mtcars_1.png]]

#+begin_src R
  library(readxl)
#+end_src

#+RESULTS:
: Warning message:
: package 'readxl' was built under R version 4.1.3

** References

Porras, E. M,"Linear Regression in R Tutorial", DataCamp, 18 Jul. 2018 [[https://www.datacamp.com/tutorial/linear-regression-R][Linear Regression in R]]
Real Python, "Linear Regression in Python", Real Python, 24 May. 2022 [[https://realpython.com/linear-regression-in-python/][Linear Regression]]
Stallman, R. M. (1984). The Emacs editor. GNU Project. [[https://www.gnu.org/software/emacs/][emacs]]
Schulte, E., Davison, C., & Dominik, C. (2016). The Org mode 8 Reference Manual. [[https://orgmode.org/manual/][org-mode]]
